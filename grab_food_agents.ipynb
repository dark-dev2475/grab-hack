{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74979c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c88de467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f040aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f225bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afa60684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing import Literal\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import MessagesState, END,StateGraph, START\n",
    "from langgraph.types import Command\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.prebuilt import create_react_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "647ac5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "members1=[\"manage_overloaded_restaurant\",\"damaged_packaging_dispute\",\"communicate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c69495f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "options=members1+[\"FINISH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a70ac0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    next:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "774ebd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Router(TypedDict):\n",
    "    \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n",
    "    next: Literal[\"manage_overloaded_restaurant\",\"damaged_packaging_dispute\",\"communicate\", 'FINISH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bab77355",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt=f\"\"\"\n",
    "You are a supervisor agent of grab-food section, tasked with managing a orchestration between the following agents: {members1\n",
    "}. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e73a7564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_food(state:State)->Command[Literal[\"manage_overloaded_restaurant\",\"damaged_packaging_dispute\",\"communicate\", 'FINISH']]:\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt},] + state[\"messages\"] # in this message the content will be the if issue is orderring if the preparation time is excess then it will call the overloaded restaurant tool\n",
    "    if state.next == \"manage_overloaded_restaurant\":\n",
    "        messages.append({\"role\": \"user\", \"content\": \"The restaurant is overloaded, please manage the situation.\"})\n",
    "    elif state.next == \"damaged_packaging_dispute\":\n",
    "        messages.append({\"role\": \"user\", \"content\": \"There is a dispute regarding damaged packaging.\"})\n",
    "    elif state.next == \"communicate\":\n",
    "        messages.append({\"role\": \"user\", \"content\": \"Please communicate with the customer.\"})\n",
    "    else:\n",
    "        messages.append({\"role\": \"user\", \"content\": \"No further action is needed.\"})\n",
    "    \n",
    "    response=llm.with_structured_output(Router).invoke(messages)\n",
    "    goto = response[\"next\"]\n",
    "    if goto==\"FINISH\":\n",
    "        goto =END\n",
    "\n",
    "    return Command(goto=goto,update={\"next\":goto})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "764fc214",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def notify_customer(delay_minutes: int) -> str:\n",
    "    \"\"\"\n",
    "    Notify the customer about long wait times and offer a voucher for the inconvenience.\n",
    "    \n",
    "    Args:\n",
    "        delay_minutes: The expected delay in minutes\n",
    "        \n",
    "    Returns:\n",
    "        A message confirming the customer has been notified\n",
    "    \"\"\"\n",
    "    return f\"Customer notified about {delay_minutes} minute delay. A voucher has been offered for the inconvenience.\"\n",
    "\n",
    "@tool\n",
    "def reroute_driver(delay_minutes: int) -> str:\n",
    "    \"\"\"\n",
    "    Re-route the driver to a short, nearby delivery while food is being prepared.\n",
    "    \n",
    "    Args:\n",
    "        delay_minutes: The expected delay in minutes\n",
    "        \n",
    "    Returns:\n",
    "        A message confirming the driver has been rerouted\n",
    "    \"\"\"\n",
    "    return f\"Driver has been rerouted to a nearby delivery that can be completed within {delay_minutes} minutes while food is being prepared.\"\n",
    "\n",
    "@tool\n",
    "def suggest_alternatives(delay_minutes: int) -> str:\n",
    "    \"\"\"\n",
    "    Find a similar restaurant nearby with a shorter wait time and propose it to the customer.\n",
    "    \n",
    "    Args:\n",
    "        delay_minutes: The expected delay in minutes\n",
    "        \n",
    "    Returns:\n",
    "        A message with alternative restaurant suggestions\n",
    "    \"\"\"\n",
    "    return f\"Customer has been provided with 3 similar restaurant alternatives with wait times under {delay_minutes//2} minutes.\"\n",
    "\n",
    "def manage_overloaded_restaurant(state: State) -> Command[Literal[\"grab_food\", \"FINISH\"]]:\n",
    "    \"\"\"\n",
    "    Handle situations where a restaurant is overloaded with orders, causing long wait times.\n",
    "    Uses tools to notify customer, reroute driver, and suggest alternatives if needed.\n",
    "    \"\"\"\n",
    "    # Create a React agent that uses our tools\n",
    "    tools = [notify_customer, reroute_driver, suggest_alternatives]\n",
    "    \n",
    "    # Create a system message to guide the agent\n",
    "    system_message = \"\"\"\n",
    "    You are a Grab Food order management agent handling an overloaded restaurant situation.\n",
    "    The kitchen prep time is 40 minutes, which is longer than usual.\n",
    "    \n",
    "    Follow these steps:\n",
    "    1. Notify the customer about the long wait time and offer a voucher\n",
    "    2. Optimize driver time by re-routing them to another nearby delivery\n",
    "    3. If the delay is critical, suggest alternative restaurants to the customer\n",
    "    \n",
    "    Use the available tools to complete these tasks efficiently.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create an agent that can use the tools to handle the overloaded restaurant\n",
    "    agent = create_react_agent(llm, tools, system_message)\n",
    "    \n",
    "    # Add the user query to the messages\n",
    "    messages = state[\"messages\"] + [\n",
    "        HumanMessage(content=\"The restaurant is overloaded with a 40-minute prep time. Handle this situation.\")\n",
    "    ]\n",
    "    \n",
    "    # Run the agent\n",
    "    agent_response = agent.invoke(messages)\n",
    "    \n",
    "    # Process the agent's response to determine next steps\n",
    "    # For simplicity, we'll just check if any action was taken\n",
    "    if any(tool.name in agent_response.content for tool in tools):\n",
    "        # If actions were taken, we can move on\n",
    "        goto = \"FINISH\" \n",
    "    else:\n",
    "        # If no action was taken, loop back to grab_food\n",
    "        goto = \"grab_food\"\n",
    "    \n",
    "    if goto == \"FINISH\":\n",
    "        goto = END\n",
    "        \n",
    "    return Command(goto=goto, update={\"next\": goto})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7164586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def initiate_mediation_flow():\n",
    "    \"\"\"driver or customer will trigger the \"at-the-door-resolutionflow then the agent manage_packaging_dispute will initiate this toolit will mainly puuase the order \"\"\"\n",
    "    return f\"the order has been paused and the dispute management is started\"\n",
    "\n",
    "@tool\n",
    "def collect_evidence():\n",
    "    \"\"\"now the interface will open at the both side once the initiate_mediation_flow started by the agent\n",
    "    it will prompt the both  parties to provide the photos of damaged packaging andd also this method will prompt both  the user and the driver some dynamic questions such as\n",
    "    , Driver: \"Was the bag sealed\n",
    "by the merchant?\", Customer: \"Was the seal intact upon\n",
    "handover?\") \"\"\"\n",
    "    return f\"the photos and the answers taken from both parties\"\n",
    "\n",
    "@tool\n",
    "def analyze_evidence():\n",
    "    \"\"\"This tool will analyze the evidence provided by both parties and determine the outcome of the dispute. and it will trigger the tools such as issue_instant_refund and exonerate_driver and log_merchant_packaging_feedback\"\"\"\n",
    "    return f\"the evidence has been analyzed and a decision has been made\"\n",
    "\n",
    "@tool\n",
    "def issue_instant_refund():\n",
    "    \"\"\"This tool will issue an instant refund to the customer if the dispute is resolved in their favor.\"\"\"\n",
    "    return f\"an instant refund has been issued to the customer\"\n",
    "\n",
    "@tool\n",
    "def exonerate_driver():\n",
    "    \"\"\"This tool will exonerate the driver if the evidence shows that they are not at fault.\"\"\"\n",
    "    return f\"the driver has been exonerated\"\n",
    "\n",
    "@tool\n",
    "def log_merchant_packaging_feedback():\n",
    "    \"\"\"This tool will log the merchant's feedback regarding the packaging.\"\"\"\n",
    "    return f\"the merchant's packaging feedback has been logged and it will warn them to manage the packaging better\"\n",
    "\n",
    "@tool\n",
    "def notify_resolution():\n",
    "    \"\"\"This tool will notify both parties about the outcome of the dispute.\"\"\"\n",
    "    return f\"both parties have been notified about the outcome of the dispute\"\n",
    "\n",
    "def damaged_packaging_dispute(state: State) -> Command[Literal[\"grab_food\", \"FINISH\"]]:\n",
    "    \"\"\"\n",
    "    Handle disputes related to damaged packaging during food delivery.\n",
    "    Uses a sequence of tools to mediate between customer and driver, collect evidence,\n",
    "    analyze the situation, and resolve the dispute fairly.\n",
    "    \"\"\"\n",
    "    # Collect all the tools needed for packaging dispute resolution\n",
    "    tools = [\n",
    "        initiate_mediation_flow,\n",
    "        collect_evidence,\n",
    "        analyze_evidence,\n",
    "        issue_instant_refund,\n",
    "        exonerate_driver,\n",
    "        log_merchant_packaging_feedback,\n",
    "        notify_resolution\n",
    "    ]\n",
    "    \n",
    "    # Create a system message to guide the agent\n",
    "    system_message = \"\"\"\n",
    "    You are a Grab Food dispute resolution agent handling a damaged packaging situation.\n",
    "    \n",
    "    Follow these steps in sequence:\n",
    "    1. Initiate the mediation flow to pause the order and start dispute management\n",
    "    2. Collect evidence from both the customer and driver (photos and answers to specific questions)\n",
    "    3. Analyze the evidence to determine who is at fault\n",
    "    4. Based on analysis:\n",
    "       - Issue a refund to the customer if appropriate\n",
    "       - Exonerate the driver if they're not at fault\n",
    "       - Log feedback for the merchant about packaging quality\n",
    "    5. Notify all parties about the resolution\n",
    "    \n",
    "    Use the available tools to complete these tasks in the correct order.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create an agent that can use the tools to handle the packaging dispute\n",
    "    agent = create_react_agent(llm, tools, system_message)\n",
    "    \n",
    "    # Add the user query to the messages\n",
    "    messages = state[\"messages\"] + [\n",
    "        HumanMessage(content=\"There is a dispute regarding damaged packaging. The customer claims the food was spilled in the bag upon arrival.\")\n",
    "    ]\n",
    "    \n",
    "    # Run the agent\n",
    "    agent_response = agent.invoke(messages)\n",
    "    \n",
    "    # Process the agent's response to determine next steps\n",
    "    # We'll check if the resolution was notified, which should be the last step\n",
    "    if \"notify_resolution\" in agent_response.content:\n",
    "        # If the dispute was fully resolved, we can finish\n",
    "        goto = \"FINISH\"\n",
    "    else:\n",
    "        # If the resolution isn't complete, go back to grab_food for further processing\n",
    "        goto = \"grab_food\"\n",
    "    \n",
    "    if goto == \"FINISH\":\n",
    "        goto = END\n",
    "        \n",
    "    return Command(goto=goto, update={\"next\": goto})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6826d8e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'communicate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m graph\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmanage_overloaded_restaurant\u001b[39m\u001b[38;5;124m\"\u001b[39m, manage_overloaded_restaurant)\n\u001b[0;32m      7\u001b[0m graph\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdamaged_packaging_dispute\u001b[39m\u001b[38;5;124m\"\u001b[39m, damaged_packaging_dispute)\n\u001b[1;32m----> 8\u001b[0m graph\u001b[38;5;241m.\u001b[39madd_node(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommunicate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mcommunicate\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'communicate' is not defined"
     ]
    }
   ],
   "source": [
    "# Create the workflow graph\n",
    "graph = StateGraph(State)\n",
    "\n",
    "# Add all nodes to the graph\n",
    "graph.add_node(\"grab_food\", grab_food)\n",
    "graph.add_node(\"manage_overloaded_restaurant\", manage_overloaded_restaurant)\n",
    "graph.add_node(\"damaged_packaging_dispute\", damaged_packaging_dispute)\n",
    "graph.add_node(\"communicate\", communicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ef5e9fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found edge starting at unknown node 'communicate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m graph\u001b[38;5;241m.\u001b[39mset_entry_point(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrab_food\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Compile the graph\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m app \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gagan\\anaconda3\\envs\\grab\\lib\\site-packages\\langgraph\\graph\\state.py:829\u001b[0m, in \u001b[0;36mStateGraph.compile\u001b[1;34m(self, checkpointer, cache, store, interrupt_before, interrupt_after, debug, name)\u001b[0m\n\u001b[0;32m    826\u001b[0m interrupt_after \u001b[38;5;241m=\u001b[39m interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[0;32m    828\u001b[0m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[1;32m--> 829\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterrupt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    833\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[0;32m    838\u001b[0m output_channels \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__root__\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschemas[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_schema]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    846\u001b[0m     ]\n\u001b[0;32m    847\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\gagan\\anaconda3\\envs\\grab\\lib\\site-packages\\langgraph\\graph\\state.py:756\u001b[0m, in \u001b[0;36mStateGraph.validate\u001b[1;34m(self, interrupt)\u001b[0m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m source \u001b[38;5;129;01min\u001b[39;00m all_sources:\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes \u001b[38;5;129;01mand\u001b[39;00m source \u001b[38;5;241m!=\u001b[39m START:\n\u001b[1;32m--> 756\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound edge starting at unknown node \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m START \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_sources:\n\u001b[0;32m    759\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    760\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGraph must have an entrypoint: add at least one edge from START to another node\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    761\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found edge starting at unknown node 'communicate'"
     ]
    }
   ],
   "source": [
    "# Set up the connections\n",
    "# The grab_food node can route to any of the specialized agents or directly to END\n",
    "graph.add_edge(\"grab_food\", \"manage_overloaded_restaurant\")\n",
    "graph.add_edge(\"grab_food\", \"damaged_packaging_dispute\")\n",
    "graph.add_edge(\"grab_food\", \"communicate\")\n",
    "graph.add_edge(\"grab_food\", END)\n",
    "\n",
    "# Each specialized agent routes back to grab_food or to END\n",
    "graph.add_edge(\"manage_overloaded_restaurant\", \"grab_food\")\n",
    "graph.add_edge(\"manage_overloaded_restaurant\", END)\n",
    "graph.add_edge(\"damaged_packaging_dispute\", \"grab_food\")\n",
    "graph.add_edge(\"damaged_packaging_dispute\", END)\n",
    "graph.add_edge(\"communicate\", \"grab_food\")\n",
    "graph.add_edge(\"communicate\", END)\n",
    "\n",
    "# Set the entry point\n",
    "graph.set_entry_point(\"grab_food\")\n",
    "\n",
    "# Compile the graph\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f84c5fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
